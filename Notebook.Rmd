---
title: "HW2"
author: "Adri√°n Arribas and Rodrigo Milton Campos"
output: html_document
date: "2025-12-19"
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
```{r, include=FALSE}
rm(list = ls())
```
# Homework 2

We choose "Exited" as the target variable for our study to determine whether a customer leaves the bank or not.

Here are the rest of the variables:

CustomerId: A unique numerical identification number for each customer.

CreditScore: A numerical value used to measure the customer's creditworthiness.

Gender: The gender of the customer (Male or Female).

Balance: The amount of money currently held in the customer's bank account.

NumOfProducts: The total number of different bank products or services used by the customer.

HasCrCard: A binary indicator showing whether the customer possesses a credit card.

IsActiveMember: A binary indicator representing whether the customer is considered an active member of the bank.

Age: The age of the customer.

Geography: The region where the customer is located (Texas, California, or Alabama).

EstimatedSalary: The projected annual salary of the customer.

Surname: The customer's last name.

Tenure: The number of years the customer has been a client of the bank.



We load all the necessary libraries:
```{r, include=FALSE}
library(mice)
library(GGally)
library(caret)
library(randomForest)
library(dplyr)
library(pROC)
```

Loading the dataset
```{r}
set.seed(123)
pre_data = read.csv("df_estados_bank.csv")
```

## Preprocessing and Visualization
```{r}
summary(pre_data)
```

Remove ID's
```{r}
pre_data = pre_data[,4:15]
```

We also remove the surnames, as we will not be using them
```{r}
pre_data = pre_data[,-10]
```

Creating dummy variables for each state
```{r}
pre_data$Geography = as.factor(pre_data$Geography)
str(pre_data$Geography)
levels(pre_data$Geography)
```

```{r}
pre_data$Texas = ifelse(pre_data$Geography == "Texas", 1, 0)
pre_data$California = ifelse(pre_data$Geography == "California", 1, 0)
pre_data$Alabama = ifelse(pre_data$Geography == "Alabama", 1, 0)

head(pre_data[c("Geography", "Alabama", "California", "Texas")])
# Removing geography
pre_data = subset(pre_data, select = -c(Geography))
```

Checking NA's
```{r}
barplot(colMeans(is.na(pre_data)), las=2)
```
Cleaning NA's
```{r}
clean = mice(pre_data, method = "rf", m = 5)
data = complete(clean)
```

It is safe to assume a tenure of 100 years is not the intended value and probably a typo or a mistake
```{r}
data = data[data$Tenure < 100,]
```

Checking for correlation between variables
```{r}
data$Gender = as.factor(data$Gender)
levels(data$Gender)
data_num = data[,-2]
data_num$Gender = as.numeric(data$Gender) - 1 # 0 for female and 1 for male
```


```{r, echo=FALSE}
R = cor(data_num)
ggcorr(data_num, label = T)
```

Factor Conversion
```{r}
#Convert Gender to Factor
data$Gender = as.factor(data$Gender)

#Convert Exited to Factor
data$Exited = as.factor(data$Exited)

#Convert Numerical Categorical Variables to Factors
data$NumOfProducts = as.factor(data$NumOfProducts)
data$HasCrCard = as.factor(data$HasCrCard)
data$IsActiveMember = as.factor(data$IsActiveMember)
data$Tenure = as.factor(data$Tenure)

#Check the final structure
str(data)
```

We visualize the target variable
```{r}
ggplot(data, aes(x = Age, fill = Exited)) +
  geom_density() +
  labs(title = "Exited Distribution by Age",
       x = "Age",
       fill = "Exited") +
  theme_minimal()
```

Although the plot of those that exited seems to be shifted towards a higher age, there is not much of a difference.

```{r}
ggplot(data, aes(x = NumOfProducts, fill = Exited)) +
  geom_bar() +
  labs(title = "Exited Distribution by Products",
       x = "Number of Products",
       fill = "Exited") +
  theme_minimal()
```

Even though the count is rather small, there is a much bigger proportion of customers that exited when looking at those with a higher number of products used.

```{r}
ggplot(data, aes(x = Balance, fill = Exited)) +
  geom_histogram() +
  labs(title = "Exited Distribution by Balance",
       x = "Balance",
       fill = "Exited") +
  theme_minimal()
```

Yields no clear conclusion as to how the balance affects the target variable.

## Classification

Data partition and display check
```{r}
train_index = createDataPartition(data$Exited, p = 0.7, list = FALSE)

# Split the data
train_data = data[train_index, ]
test_data  = data[-train_index, ]

# Display
prop.table(table(train_data$Exited))
prop.table(table(test_data$Exited))
```

### Random Forest
Training the random forest
```{r}
rf_model = randomForest(
  Exited ~ ., 
  data = train_data, 
  ntree = 500,
  importance = TRUE
)

# Print the model summary
print(rf_model)
```
Evaluating the random forest
```{r}
rf_predictions <- predict(rf_model, newdata = test_data)

conf_matrix_rf <- confusionMatrix(rf_predictions, 
                                  test_data$Exited, 
                                  positive = "1")

conf_matrix_rf
```

#### ROC for Random Forest
We use the ROC curve to obtain the optimal threshold.
```{r}
rf_prob <- predict(rf_model, newdata = test_data, type = "prob")
plot.roc(test_data$Exited, rf_prob[,2], col="darkblue", print.auc = TRUE,  auc.polygon=TRUE, grid=c(0.1, 0.2),
         grid.col=c("green", "red"), max.auc.polygon=TRUE,
         auc.polygon.col="lightblue", print.thres=TRUE)
```

We seem to obtain an optimal threshold of about 0.15
It makes sense for us to obtain a low threshold due to the imbalance we can see in the positive and negative values for the target variable.
```{r}
threshold_1 = 0.15

# New model with "optimal" threshold
rf_model = randomForest(
  Exited ~ ., 
  data = train_data, 
  ntree = 500,
  importance = TRUE,
  cutoff = c(0.85, 0.15)
)

rf_predictions <- predict(rf_model, newdata = test_data)

conf_matrix_rf <- confusionMatrix(rf_predictions, 
                                  test_data$Exited, 
                                  positive = "1")

conf_matrix_rf
```

It seems to have traded a substantial increase in Sensitivity in exchange for a noticeable decrease in Specificity. The Accuracy is also lower.



### Logistic Regression
Emphasis on interpretation
```{r}
glm_model = glm(Exited ~ ., 
                 data = train_data, 
                 family = binomial(link = "logit"))

summary(glm_model)
```

We can determine what variables are more significant for predicting the exit of customers by looking at the "Estimate" column while bearing in mind the strength of theses predictors is given by the p-value assigned to them. Therefore, we check primarily those with "***" (smallest p-value). Positive values mean a higher value for the input variable yield a higher probability of the customer leaving.

Taking this into account, it seems that Age is a factor that increases the risk of churn (positive Estimate value), and so is being from Alabama (or registering there for the bank's services), as we can see from the negative Estimate values for California and Texas.

Being male (Gender) and being an active member are two factors that decrease the risk of churn, as can be determined by seeing the negative values for Estimate.

```{r}
# Predicting probabilities on the test data
glm_prob = predict(glm_model, newdata = test_data, type = "response")

# Converting probabilities to class predictions (using default threshold of 0.5)
glm_prediction = factor(ifelse(glm_prob > 0.5, 1, 0), levels = c("0", "1"))

# Creating the Confusion Matrix
conf_matrix_glm = confusionMatrix(glm_prediction, 
                                  test_data$Exited, 
                                  positive = "1")

# Print results
conf_matrix_glm
```
#### ROC for Logistic Regression

We use the ROC curve to obtain the optimal threshold.
```{r}
plot.roc(test_data$Exited, glm_prob, col="darkblue", print.auc = TRUE,  auc.polygon=TRUE, grid=c(0.1, 0.2),
         grid.col=c("green", "red"), max.auc.polygon=TRUE,
         auc.polygon.col="lightblue", print.thres=TRUE)
```

We can try a threshold of around 0.2:
```{r}
threshold_2 = 0.2

# Evaluation of Logistic Regression Model with "optimal" threshold
glm_prediction = factor(ifelse(glm_prob > threshold_2, 1, 0), levels = c("0", "1"))


conf_matrix_glm = confusionMatrix(glm_prediction, 
                                  test_data$Exited, 
                                  positive = "1")

conf_matrix_glm
```

It seems to have traded a substantial increase in Sensitivity in exchange for a slight decrease in Specificity. The Accuracy is also a bit lower.


#### Cost Matrix

We define a possible cost matrix and obtain the optimal threshold for it.

```{r}
churn_cost = 500          # Lifetime value of a client
retention = 50     # Cost of the incentive

thresholds = seq(0.05, 0.95, 0.05)
total_profits = data.frame(Threshold = thresholds, Profit = rep(0, length(thresholds)))
for (i in 1:length(thresholds)) {
 threshold = thresholds[i] 
 preds = ifelse(glm_prob >= threshold, 1, 0)
 
 tp = sum(preds == 1 & test_data$Exited == 1)
 fp = sum(preds == 1 & test_data$Exited == 0)
 
 total_profits$Profit[i] = (tp * (churn_cost - retention)) - (fp * retention)
}

ggplot(total_profits, aes(x = Threshold, y = Profit))+
  geom_line(color = "blue")+
  geom_vline(xintercept = thresholds[which.max(total_profits$Profit)], linetype="dashed", color="red")
```

We can observe the best threshold for economic gain we have tested is 0.1, which makes sense given the much higher cost of loosing a customer with respect to offering an incentive for retention.


## Feature Selection

```{r}
importance(rf_model) # Raw scores
varImpPlot(rf_model, main = "Variable Importance")
```

Looking at the Variable Importance graph we can choose NumOfProducts, Age, IsActiveMember, Balance and Geography (divided in California, Alabama and Texas) as the 5 most important variables for the Random Forest.

```{r}
## Model Comparison: Reduced Feature Set

# Define the reduced formula based on feature importance analysis:
# We will use the thresholds obtained by the ROC curves
reduced_formula = Exited ~ Age + Balance + NumOfProducts + CreditScore + IsActiveMember + California + Alabama + Texas

# Training Reduced Random Forest
rf_reduced = randomForest(
  reduced_formula, 
  data = train_data, 
  ntree = 500,
  importance = TRUE,
  cutoff = c(1 - threshold_1, threshold_1)
)

# Evaluating Reduced Random Forest
rf_reduced_pred = predict(rf_reduced, newdata = test_data)
conf_matrix_rf_reduced = confusionMatrix(rf_reduced_pred, 
                                        test_data$Exited, 
                                        positive = "1")


# Training Reduced Logistic Regression
glm_reduced = glm(reduced_formula, 
                 data = train_data, 
                 family = binomial(link = "logit"))

# Evaluating Reduced Logistic Regression
glm_reduced_prob = predict(glm_reduced, newdata = test_data, type = "response")
glm_reduced_pred = factor(ifelse(glm_reduced_prob > threshold_2, 1, 0), levels = c("0", "1"))
conf_matrix_glm_reduced = confusionMatrix(glm_reduced_pred, 
                                        test_data$Exited, 
                                        positive = "1")
```
```{r}
# Function to extract key metrics
extract_metrics = function(conf_matrix, model_name) {
  data.frame(
    Model = model_name,
    Accuracy = conf_matrix$overall['Accuracy'],
    Sensitivity = conf_matrix$byClass['Sensitivity'],
    Specificity = conf_matrix$byClass['Specificity'],
    F1_Score = conf_matrix$byClass['F1']
  )
}

# Combining all results
comparison_table = rbind(
  extract_metrics(conf_matrix_rf, "RF_Full"),
  extract_metrics(conf_matrix_rf_reduced, "RF_Reduced"),
  extract_metrics(conf_matrix_glm, "GLM_Full"),
  extract_metrics(conf_matrix_glm_reduced, "GLM_Reduced")
)

# Print final comparison table
print(comparison_table)
```